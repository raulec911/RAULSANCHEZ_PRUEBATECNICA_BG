{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Asistente Financiero con RAG y Tools\n",
        "\n",
        "## A) Instalaci√≥n de dependencias\n",
        "\n",
        "En tu Jupyter Notebook (o terminal) ejecuta:\n",
        "\n",
        "```bash\n",
        "pip install \\\n",
        "  langchain[pypdf] \\        # LangChain + soporte PDF (PyPDFLoader)\n",
        "  openai \\                  # Cliente para modelos de OpenAI\n",
        "  tiktoken \\                # Tokenizador necesario para embeddings\n",
        "  faiss-cpu \\               # √çndice vectorial FAISS en CPU\n",
        "  gradio \\                  # Framework para interfaz web\n",
        "  requests \\                # Llamadas HTTP (API de conversi√≥n de divisas)\n",
        "  pypdf \\                   # Librer√≠a de lectura de PDF (por si falla el extra)\n",
        "  unstructured \\            # Loader alternativo para PDFs complejos\n",
        "  python-dotenv             # Para cargar variables desde .env\n"
      ],
      "metadata": {
        "id": "KvAmAOz9nezg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B) Arquitectura de la Soluci√≥n\n",
        "\n",
        "La siguiente arquitectura muestra c√≥mo se orquestan los distintos componentes para ofrecer:\n",
        "\n",
        "1. **Preguntas sobre PDF** mediante RAG (Retrieval-Augmented Generation).  \n",
        "2. **Conversi√≥n de divisas** de forma independiente.  \n",
        "\n",
        "---\n",
        "\n",
        "## 1. Capa de Presentaci√≥n (Frontend)\n",
        "\n",
        "- **Gradio Blocks** embebido en Jupyter o servidor local.  \n",
        "- Dos secciones claramente separadas:  \n",
        "  1. **Consultas al Informe Financiero (PDF)**  \n",
        "     - Bot√≥n **Cargar PDF**  \n",
        "     - Cuadro de texto y bot√≥n **Enviar consulta PDF**  \n",
        "     - Caja de texto para el estado del PDF  \n",
        "  2. **Conversi√≥n de Moneda**  \n",
        "     - Cuadro de texto para la frase de conversi√≥n (p.ej. `150 EUR a USD`)  \n",
        "     - Bot√≥n **Convertir**  \n",
        "     - Caja de texto para el resultado de la conversi√≥n  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. Capa de Orquestaci√≥n (Backend)\n",
        "\n",
        "- **Controlador Gradio**  \n",
        "  - Captura eventos de los botones y mapea a las funciones Python:  \n",
        "    - `load_pdf`  \n",
        "    - `answer_pdf_query`  \n",
        "    - `answer_conversion_query`  \n",
        "- **Estado Global**  \n",
        "  - `vectorstore` y `qa_chain` se inicializan tras cargar el PDF.  \n",
        "  - La herramienta de conversi√≥n es independiente de ese estado y siempre est√° disponible.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Pipeline RAG para QA sobre PDF\n",
        "\n",
        "1. **Document Loader**  \n",
        "   - `PyPDFLoader` o `UnstructuredPDFLoader` fragmenta el PDF en trozos sem√°nticos.  \n",
        "2. **Embeddings**  \n",
        "   - `OpenAIEmbeddings` convierte cada fragmento en un vector de punto flotante.  \n",
        "3. **Vector Store**  \n",
        "   - `FAISS` indexa localmente todos los vectores para b√∫squeda de similitud.  \n",
        "4. **RetrievalQA Chain**  \n",
        "   - Al recibir una pregunta:  \n",
        "     - Recupera los fragmentos m√°s relevantes de FAISS.  \n",
        "     - Pasa esos fragmentos a `ChatOpenAI` para generar la respuesta final.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Servicio de Conversi√≥n de Moneda\n",
        "\n",
        "- **Parser Regex** en `answer_conversion_query` detecta patrones:  "
      ],
      "metadata": {
        "id": "vxjSU8qlnivK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C) Mejoras Futuras\n",
        "\n",
        "- **Preprocesamiento avanzado**: soportar OCR (PDF escaneados) y extraer metadatos (fecha, autor).  \n",
        "- **UI m√°s rica**: a√±adir historial de consultas y chat continuo para contextualizar preguntas.  \n",
        "- **Persistencia del √≠ndice**: guardar el vectorstore en disco o en un servicio gestionado para evitar reindexar.  \n",
        "- **Nuevas herramientas**: incorporar calculadora financiera y generaci√≥n de gr√°ficos din√°micos.  \n",
        "- **Optimizaci√≥n y cach√©**: batch de embeddings, caching de conversiones de divisas y l√≠mites de tama√±o de archivo.  \n"
      ],
      "metadata": {
        "id": "TQ10gGTqnk0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def silent_install(package):\n",
        "    try:\n",
        "        subprocess.check_call(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL\n",
        "        )\n",
        "        print(f\"‚úÖ {package} instalado (o ya estaba).\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error instalando {package}: {e}\")\n",
        "\n",
        "# Lista de paquetes\n",
        "packages = [\n",
        "    \"openai\",\n",
        "    \"faiss-cpu\",\n",
        "    \"gradio\",\n",
        "    \"requests\",\n",
        "    \"pypdf\",\n",
        "    \"langchain-community\",\n",
        "    \"tiktoken\",\n",
        "    \"langchain[pypdf]\"\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    silent_install(pkg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS-NKUXRnn0f",
        "outputId": "074e567d-3e3f-4f84-819b-4ecab9f29816"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ openai instalado (o ya estaba).\n",
            "‚úÖ faiss-cpu instalado (o ya estaba).\n",
            "‚úÖ gradio instalado (o ya estaba).\n",
            "‚úÖ requests instalado (o ya estaba).\n",
            "‚úÖ pypdf instalado (o ya estaba).\n",
            "‚úÖ langchain-community instalado (o ya estaba).\n",
            "‚úÖ tiktoken instalado (o ya estaba).\n",
            "‚úÖ langchain[pypdf] instalado (o ya estaba).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Carga variables de entorno desde .env (si existe)\n",
        "if os.path.exists(\".env\"):\n",
        "    load_dotenv(\".env\")\n",
        "\n",
        "# Compatibilidad con loaders de PDF\n",
        "try:\n",
        "    from langchain.document_loaders import PyPDFLoader as PDFLoader\n",
        "except ImportError:\n",
        "    from langchain.document_loaders import UnstructuredPDFLoader as PDFLoader\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Inicializar LLM y embeddings\n",
        "env_api_key = os.getenv(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\"\n",
        "llm = ChatOpenAI(openai_api_key=env_api_key, temperature=0)\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=env_api_key)\n",
        "\n",
        "# Variables globales para PDF QA\n",
        "global vectorstore, qa_chain\n",
        "vectorstore = None\n",
        "qa_chain = None\n",
        "\n",
        "# -------------------------------------\n",
        "# Tool de conversi√≥n de divisas (no requiere API key)\n",
        "def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
        "    \"\"\"Convierte amount de from_currency a to_currency usando open.er-api.com (sin API key)\"\"\"\n",
        "    url = f\"https://open.er-api.com/v6/latest/{from_currency.upper()}\"\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=10)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        if data.get(\"result\") != \"success\":\n",
        "            return f\"‚ùå API error: {data.get('error-type', data)}\"\n",
        "        rates = data.get(\"rates\", {})\n",
        "        rate = rates.get(to_currency.upper())\n",
        "        if rate is None:\n",
        "            return f\"‚ùå Tasa no encontrada para {to_currency.upper()}. Disponible: {list(rates.keys())[:5]}...\"\n",
        "        converted = rate * amount\n",
        "        return f\"{amount:.2f} {from_currency.upper()} = {converted:.2f} {to_currency.upper()}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error en conversi√≥n: {e}\"\n",
        "# -------------------------------------\n",
        "\n",
        "# Carga y preparaci√≥n del PDF para RAG\n",
        "\n",
        "def load_pdf(pdf_file):\n",
        "    \"\"\"Carga el PDF, construye vectorstore y la cadena RAG para QA\"\"\"\n",
        "    global vectorstore, qa_chain #vectorstore: Indice vectorial del contenido del PDF, qa_chain: Cadena RAG configurada para responder preguntas.\n",
        "    try:\n",
        "        loader = PDFLoader(pdf_file.name) # PDFLoader: Cargador de PDFs (LangChain).\n",
        "        docs = loader.load_and_split() # Lee el PDF y Divide su contenido en fragmentos para poder vectorizarlos de forma eficiente. Obtiendo una lista de documentos.\n",
        "        # FAISS: Es una librer√≠a de Facebook para b√∫squedas r√°pidas en vectores.\n",
        "        # Aqu√≠ se convierten los fragmentos de texto en vectores usando los embeddings.\n",
        "        # Luego, se almacenan los vectores en un √≠ndice FAISS para poder buscar contenido similar al hacer preguntas.\n",
        "        vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "        # Se crea una cadena RAG (Retrieval-Augmented Generation).\n",
        "        # llm=llm: Modelo de lenguaje.\n",
        "        # chain_type=\"stuff\": Tipo b√°sico de cadena donde se \"inyectan\" los textos recuperados directamente al LLM.\n",
        "        # retriever=vectorstore.as_retriever(): Conectas el √≠ndice vectorial para que, al recibir una pregunta, busque los fragmentos relevantes del PDF.\n",
        "        # return_source_documents=False: Solo devuelve la respuesta, sin mostrar los documentos fuente.\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=vectorstore.as_retriever(),\n",
        "            return_source_documents=False\n",
        "        )\n",
        "        return \"üìÑ PDF cargado y listo para consultas\"\n",
        "    except Exception as exc:\n",
        "        return f\"‚ùå Error al cargar PDF: {exc}\"\n",
        "\n",
        "# Funciones de respuesta separadas\n",
        "\n",
        "def answer_pdf_query(query: str) -> str:\n",
        "    \"\"\"Responde preguntas sobre el PDF usando RAG\"\"\"\n",
        "    if qa_chain is None:\n",
        "        return \"‚ö†Ô∏è Primero carga un PDF antes de preguntar al informe.\"\n",
        "    try:\n",
        "        return qa_chain.run(query)\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error al generar respuesta PDF: {e}\"\n",
        "\n",
        "\n",
        "def answer_conversion_query(query: str) -> str:\n",
        "    \"\"\"Responde conversiones de moneda independientemente del PDF\"\"\"\n",
        "    # Regex: cantidad + 3-letras + 'a'|'en' + 3-letras\n",
        "    match = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\\s*([A-Za-z]{3})\\s+(?:a|en)\\s+([A-Za-z]{3})\", query)\n",
        "    if match:\n",
        "        amt, frm, to = match.groups()\n",
        "        try:\n",
        "            return convert_currency(float(amt), frm, to)\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error interno conversi√≥n: {e}\"\n",
        "    return \"‚ö†Ô∏è Usa formato: '<monto> <MONEDA_ORIGEN> a|en <MONEDA_DESTINO>' (p.ej. '100 USD a EUR')\"\n",
        "\n",
        "# Construcci√≥n de la interfaz Gradio\n",
        "demo = gr.Blocks()\n",
        "with demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "                  <center><h1>Banco Guayaquil</h1></center>\n",
        "                  <center><h3>Asistente Financiero: PDF + Conversi√≥n de Moneda</h3></center>\n",
        "               \"\"\")\n",
        "\n",
        "    # Secci√≥n PDF QA\n",
        "    gr.Markdown(\"## Consultas al Informe Financiero (PDF)\")\n",
        "    with gr.Row():\n",
        "        pdf_input = gr.File(label=\"Sube tu informe financiero (PDF)\")\n",
        "        pdf_load_btn = gr.Button(\"Cargar PDF\")\n",
        "    status = gr.Textbox(label=\"Estado PDF\", interactive=False)\n",
        "    pdf_query = gr.Textbox(label=\"Pregunta\", lines=2, placeholder=\"Pregunta al informe... (p.ej. 'Total de activos 2021')\")\n",
        "    pdf_submit = gr.Button(\"Enviar consulta PDF\")\n",
        "    pdf_output = gr.Textbox(label=\"Respuesta PDF\", interactive=False)\n",
        "\n",
        "    pdf_load_btn.click(fn=load_pdf, inputs=pdf_input, outputs=status)\n",
        "    pdf_submit.click(fn=answer_pdf_query, inputs=pdf_query, outputs=pdf_output)\n",
        "\n",
        "    # Secci√≥n Conversi√≥n de Moneda\n",
        "    gr.Markdown(\"## Conversi√≥n de Moneda\")\n",
        "    conv_query = gr.Textbox(label=\"Pregunta\", lines=1, placeholder=\"Ej. '150 EUR a USD'\")\n",
        "    conv_btn = gr.Button(\"Convertir\")\n",
        "    conv_output = gr.Textbox(label=\"Resultado Conversi√≥n\", interactive=False)\n",
        "\n",
        "    conv_btn.click(fn=answer_conversion_query, inputs=conv_query, outputs=conv_output)\n",
        "\n",
        "# Lanzar en Jupyter / Notebook con share URL\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "L4feH7VGnwS9",
        "outputId": "80a8c381-2136-4b9a-e033-71114e645dd1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-7c1342bc9814>:24: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(openai_api_key=env_api_key, temperature=0)\n",
            "<ipython-input-1-7c1342bc9814>:25: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key=env_api_key)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ca8388c25bec55be9e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ca8388c25bec55be9e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQeilcx-pWWI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}